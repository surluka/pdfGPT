from dotenv import load_dotenv
load_dotenv()

import streamlit as st

from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

# ë‹¨ê³„ 1: ë¬¸ì„œ ë¡œë“œ(Load Documents)
loader = PyMuPDFLoader("pdfGPTdata.pdf")
docs = loader.load()

# ë‹¨ê³„ 2: ë¬¸ì„œ ë¶„í• (Split Documents)
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)
split_documents = text_splitter.split_documents(docs)

# ë‹¨ê³„ 3: ì„ë² ë”©(Embedding) ìƒì„±
embeddings = OpenAIEmbeddings()

# ë‹¨ê³„ 4: DB ìƒì„±(Create DB) ë° ì €ì¥
# ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)

# ë‹¨ê³„ 5: ê²€ìƒ‰ê¸°(Retriever) ìƒì„±
# ë¬¸ì„œì— í¬í•¨ë˜ì–´ ìˆëŠ” ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìƒì„±í•©ë‹ˆë‹¤.
retriever = vectorstore.as_retriever()

# ë‹¨ê³„ 6: í”„ë¡¬í”„íŠ¸ ìƒì„±(Create Prompt)
# í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
prompt = PromptTemplate.from_template(
    """You are an assistant for question-answering tasks. 
Use the following pieces of retrieved context to answer the question. 
If you don't know the answer, just say that you don't know. 
Answer in Korean.

#Question: 
{question} 
#Context: 
{context} 

#Answer:"""
)

# ë‹¨ê³„ 7: ì–¸ì–´ëª¨ë¸(LLM) ìƒì„±
# ëª¨ë¸(LLM) ì„ ìƒì„±í•©ë‹ˆë‹¤.
llm = ChatOpenAI(model_name="gpt-4o-mini-2024-07-18", temperature=0.3)

# ë‹¨ê³„ 8: ì²´ì¸(Chain) ìƒì„±
chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# Streamlit UI
st.title("ğŸ“„ PDF ê¸°ë°˜ Q&A ì±—ë´‡")

# ì²´ì¸ ì‹¤í–‰(Run Chain)
# ë¬¸ì„œì— ëŒ€í•œ ì§ˆì˜ë¥¼ ì…ë ¥í•˜ê³ , ë‹µë³€ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
# """ question = "ê¹€ê²½í›ˆì”¨ì˜ ê²°ì„ ì¼ìˆ˜ë¥¼ ì•Œë ¤ì¤˜"
# response = chain.invoke(question)
# print(response) """

question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
if st.button("ì§ˆë¬¸í•˜ê¸°"):
    if question:
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            response = chain.invoke(question)
        st.write("**ë‹µë³€:**", response.strip())
    else:
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")